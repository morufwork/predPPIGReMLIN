{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8d1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging\n",
    "#import matplotlib.pyplot as plt\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from Bio.PDB import Residue\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "\n",
    "\n",
    "# Define interaction criteria\n",
    "interaction_criteria = {\n",
    "    \"ARM_STACK\": {\"atomic_type1\": \"ARM\", \"atomic_type2\": \"ARM\", \"min_dist\": 1.5, \"max_dist\": 3.5},\n",
    "    \"H_BOND\": {\"atomic_type1\": \"ACP\", \"atomic_type2\": \"DON\", \"min_dist\": 2.0, \"max_dist\": 3.0},\n",
    "    \"HYDROPHOBIC\": {\"atomic_type1\": \"HPB\", \"atomic_type2\": \"HPB\", \"min_dist\": 2.0, \"max_dist\": 3.8},\n",
    "    \"REPULSIVE\": {\"atomic_type1\": \"POS\", \"atomic_type2\": \"POS\", \"min_dist\": 2.0, \"max_dist\": 6.0},\n",
    "    \"REPULSIVE\": {\"atomic_type1\": \"NEG\", \"atomic_type2\": \"NEG\", \"min_dist\": 2.0, \"max_dist\": 6.0},\n",
    "    \"SALT_BRIDGE\": {\"atomic_type1\": \"POS\", \"atomic_type2\": \"NEG\", \"min_dist\": 2.0, \"max_dist\": 6.0},\n",
    "    \"SS_BRIDGE\": {\"atomic_type1\": \"SG\", \"atomic_type2\": \"SG\", \"min_dist\": 2.0, \"max_dist\": 2.2},\n",
    "}\n",
    "\n",
    "# Full names mapping\n",
    "type_full_names = {\n",
    "    \"ACP\": \"Acceptor\",\n",
    "    \"DON\": \"Donor\",\n",
    "    \"POS\": \"Positive\",\n",
    "    \"NEG\": \"Negative\",\n",
    "    \"HPB\": \"Hydrophobic\",\n",
    "    \"ARM\": \"Aromatic\",\n",
    "    \"HYDROPHOBIC\": \"Hydrophobic\",\n",
    "    \"SALT_BRIDGE\": \"Salt bridge\",\n",
    "    \"ARM_STACK\": \"Aromatic\",\n",
    "    \"H_BOND\": \"Hydrogen bond\",\n",
    "    \"REPULSIVE\": \"Repulsive\",\n",
    "    \"SS_BRIDGE\": \"Disulfide Bridge\"\n",
    "}\n",
    "\n",
    "# Amino acid to atom types mapping (same as given in the provided data)\n",
    "# Amino acid to atom types mapping\n",
    "amino_acid_atoms = {\n",
    "    \"ALA\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\"},\n",
    "    \"ARG\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \"CD\": None, \n",
    "            \"NE\": \"POS,DON\", \"CZ\": \"POS\", \"NH1\": \"POS,DON\", \"NH2\": \"POS,DON\"},\n",
    "    \"ASN\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": None, \n",
    "            \"OD1\": \"ACP\", \"ND2\": \"DON\"},\n",
    "    \"ASP\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": None, \n",
    "            \"OD1\": \"NEG,ACP\", \"OD2\": \"NEG,ACP\"},\n",
    "    \"CYS\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"SG\": \"DON,ACP\"},\n",
    "    \"GLN\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"CD\": None, \"OE1\": \"ACP\", \"NE2\": \"DON\"},\n",
    "    \"GLU\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"CD\": None, \"OE1\": \"NEG,ACP\", \"OE2\": \"NEG,ACP\"},\n",
    "    \"GLY\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\"},\n",
    "    \"HIS\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"ARM\", \n",
    "            \"ND1\": \"ARM,POS\", \"CD2\": \"ARM\", \"CE1\": \"ARM\", \"NE2\": \"ARM,POS\"},\n",
    "    \"ILE\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG1\": \"HPB\", \n",
    "            \"CG2\": \"HPB\", \"CD1\": \"HPB\"},\n",
    "    \"LEU\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"CD1\": \"HPB\", \"CD2\": \"HPB\"},\n",
    "    \"LYS\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"CD\": \"HPB\", \"CE\": None, \"NZ\": \"POS,DON\"},\n",
    "    \"MET\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"SD\": \"ACP\", \"CE\": \"HPB\"},\n",
    "    \"PHE\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB,ARM\", \n",
    "            \"CD1\": \"HPB,ARM\", \"CD2\": \"HPB,ARM\", \"CE1\": \"HPB,ARM\", \"CE2\": \"HPB,ARM\", \n",
    "            \"CZ\": \"HPB,ARM\"},\n",
    "    \"PRO\": {\"N\": None, \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB\", \n",
    "            \"CD\": None},\n",
    "    \"SER\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": None, \"OG\": \"DON,ACP\"},\n",
    "    \"THR\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": None, \"OG1\": \"DON,ACP\", \n",
    "            \"CG2\": \"HPB\"},\n",
    "    \"TRP\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB,ARM\", \n",
    "            \"CD1\": \"ARM\", \"CD2\": \"HPB,ARM\", \"NE1\": \"ARM,DON\", \"CE2\": \"ARM\", \n",
    "            \"CE3\": \"HPB,ARM\", \"CZ2\": \"HPB,ARM\", \"CZ3\": \"HPB,ARM\", \"CH2\": \"HPB,ARM\"},\n",
    "    \"TYR\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \"CG\": \"HPB,ARM\", \n",
    "            \"CD1\": \"HPB,ARM\", \"CD2\": \"HPB,ARM\", \"CE1\": \"HPB,ARM\", \"CE2\": \"HPB,ARM\", \n",
    "            \"CZ\": \"ARM\", \"OH\": \"DON,ACP\"},\n",
    "    \"VAL\": {\"N\": \"DON\", \"CA\": None, \"C\": None, \"O\": \"ACP\", \"CB\": \"HPB\", \n",
    "            \"CG1\": \"HPB\", \"CG2\": \"HPB\"},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96bb2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "    \n",
    "def parse_residue_id(residue_id):\n",
    "    \"\"\"\n",
    "    Parses a residue ID string into a Biopython Residue object.\n",
    "\n",
    "    Args:\n",
    "        residue_id (str): Residue ID in the format \"CHAIN_RESNAME_RESSEQ\".\n",
    "\n",
    "    Returns:\n",
    "        Residue: A Residue object with parsed attributes.\n",
    "    \"\"\"\n",
    "    chain, resname, resseq = residue_id.split(\"_\")\n",
    "    resseq = int(resseq)  # Convert residue sequence to integer\n",
    "    return Residue.Residue((' ', resseq, ' '), resname, chain)\n",
    "\n",
    "\n",
    "\n",
    "def filter_surface_residues(protein_sasa_results, sasa_threshold):\n",
    "    \"\"\"\n",
    "    Filters surface residues based on SASA results for multiple protein structures.\n",
    "\n",
    "    Args:\n",
    "        protein_sasa_results (dict): SASA results for multiple protein structures,\n",
    "                                     keyed by structure ID (PDB file name), \n",
    "                                     with residues and their SASA values.\n",
    "\n",
    "    Returns:\n",
    "        dict: Filtered residues for each protein structure, \n",
    "              keyed by structure ID, containing only residues meeting the surface threshold.\n",
    "    \"\"\"\n",
    "    filtered_results = {}\n",
    "\n",
    "    for structure_id, residues_dict in protein_sasa_results.items():\n",
    "        # Step 3: Identify the maximum SASA for the current protein structure\n",
    "        max_sasa = max(residues_dict.values())\n",
    "\n",
    "        # Step 4: Set a threshold for identifying surface residues\n",
    "        surface_threshold = sasa_threshold * max_sasa\n",
    "\n",
    "        # Step 5: Identify and collect surface residues\n",
    "        surface_residues = [\n",
    "            parse_residue_id(residue_id)\n",
    "            for residue_id, sasa_value in residues_dict.items()\n",
    "            if sasa_value >= surface_threshold\n",
    "        ]\n",
    "\n",
    "        # Store the filtered results for the current protein\n",
    "        filtered_results[structure_id] = surface_residues\n",
    "\n",
    "    return filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5622f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_graphs(file_path):\n",
    "    \"\"\"\n",
    "    Loads all graphs from a saved file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file containing saved graphs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of graphs, keyed by structure IDs.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        graph_dict = pickle.load(file)\n",
    "    print(f\"All graphs loaded from {file_path}\")\n",
    "    return graph_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b68dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_surface_residues_to_graph(graph, surface_residues):\n",
    "    mapped_surface_nodes = []\n",
    "    residue_dict = {}\n",
    "    \n",
    "    for surface_res in surface_residues:\n",
    "        res_name = surface_res.get_resname()\n",
    "        res_id = surface_res.id[1]\n",
    "        surface_node_key = f\"{res_name}_{res_id}\"\n",
    "        \n",
    "        # Check if this residue is in the graph\n",
    "        if surface_node_key in graph.nodes:\n",
    "            mapped_surface_nodes.append(surface_node_key)\n",
    "            residue_dict[surface_node_key] = surface_res  # Store residue for later retrieval\n",
    "            \n",
    "            \n",
    "    return mapped_surface_nodes,  residue_dict\n",
    "\n",
    "\n",
    "def get_adjacent_nodes_and_edges(graph, surface_node):\n",
    "    # Get the adjacent residues (1-hop neighbors)\n",
    "    neighbors = list(graph.neighbors(surface_node))\n",
    "    edges = list(graph.edges(surface_node, data=True))  # Edges with data (interaction_type, distance, etc.)\n",
    "    \n",
    "    return neighbors, edges\n",
    "\n",
    "\n",
    "\n",
    "def get_adjacent_adjacent_nodes_and_edges(graph, neighbor_nodes):\n",
    "    adjacent_adjacent_nodes = set()  # To avoid duplicate entries\n",
    "    adjacent_adjacent_edges = []\n",
    "    \n",
    "    for neighbor in neighbor_nodes:\n",
    "        # Get neighbors of the neighbor (2-hop neighbors)\n",
    "        next_neighbors = list(graph.neighbors(neighbor))\n",
    "        next_edges = list(graph.edges(neighbor, data=True))\n",
    "        \n",
    "        adjacent_adjacent_nodes.update(next_neighbors)  # Add next level of neighbors\n",
    "        adjacent_adjacent_edges.extend(next_edges)      # Add next level of edges\n",
    "    \n",
    "    return list(adjacent_adjacent_nodes), adjacent_adjacent_edges\n",
    "\n",
    "\n",
    "atom_encoding = {\n",
    "        'ACP': 1,\n",
    "        'DON': 2,\n",
    "        'POS': 3,\n",
    "        'NEG': 4,\n",
    "        'HPB': 5,\n",
    "        'ARM': 6,        \n",
    "        None: 0  # Use 0 or any encoding for `None`\n",
    "    }\n",
    "  \n",
    "    \n",
    "def encode_atom_categories(atom_categories, atom_encoding, max_length):\n",
    "    # Convert dictionary of atom categories to a list of encoded values\n",
    "    encoded = [atom_encoding.get(value, 0) for value in atom_categories.values()]\n",
    "    # Pad encoded list to ensure it has `max_length`\n",
    "    return encoded + [0] * (max_length - len(encoded))\n",
    "\n",
    "\n",
    "# Helper function to extract node features and edges for each mapped surface node and adjacent nodes\n",
    "def extract_subgraph(graph, mapped_surface_nodes):\n",
    "    nodes, edges = [], []\n",
    "    max_atom_categories_length = max(len(amino_acid_atoms[res_name]) for res_name in amino_acid_atoms)\n",
    "\n",
    "    for surface_node in mapped_surface_nodes:\n",
    "        if surface_node in graph:\n",
    "            res_name, res_id = surface_node.split('_')\n",
    "            atom_categories = amino_acid_atoms[res_name]\n",
    "            encoded_atom_categories = encode_atom_categories(atom_categories, atom_encoding, max_atom_categories_length)\n",
    "            \n",
    "            # Convert each node feature list to a tensor with consistent length\n",
    "            node_tensor = torch.tensor([int(res_id)] + encoded_atom_categories, dtype=torch.float)\n",
    "            nodes.append(node_tensor)\n",
    "            \n",
    "        adjacent_nodes, adjacent_edges = get_adjacent_nodes_and_edges(graph, surface_node)\n",
    "        adjacent_adjacent_nodes, adjacent_adjacent_edges = get_adjacent_adjacent_nodes_and_edges(graph, adjacent_nodes)\n",
    "        \n",
    "        # Ensure edges are stored as integer pairs\n",
    "        edges.extend([\n",
    "            (int(edge[0].split('_')[1]), int(edge[1].split('_')[1]))\n",
    "            for edge in adjacent_edges\n",
    "        ])\n",
    "        edges.extend([\n",
    "            (int(edge[0].split('_')[1]), int(edge[1].split('_')[1]))\n",
    "            for edge in adjacent_adjacent_edges\n",
    "        ])\n",
    "        \n",
    "        for adj_node in adjacent_nodes + adjacent_adjacent_nodes:\n",
    "            if adj_node in graph:\n",
    "                res_name, res_id = adj_node.split('_')\n",
    "                atom_categories = amino_acid_atoms[res_name]\n",
    "                encoded_atom_categories = encode_atom_categories(atom_categories, atom_encoding, max_atom_categories_length)\n",
    "                \n",
    "                adj_node_tensor = torch.tensor([int(res_id)] + encoded_atom_categories, dtype=torch.float)\n",
    "                nodes.append(adj_node_tensor)\n",
    "                \n",
    "    nodes_tensor = torch.stack(nodes)\n",
    "    edges_tensor = torch.tensor(edges, dtype=torch.long).t().contiguous()  # Ensure edges are in long format\n",
    "    \n",
    "    return nodes_tensor, edges_tensor\n",
    "\n",
    "\n",
    "# Define function to create a Data object for each protein graph from parsed PDB data\n",
    "def create_protein_data(graph_p1, graph_p2, surface_residues_p1, surface_residues_p2, class_label):\n",
    "    # Map surface residues to graph nodes and retrieve subgraphs\n",
    "    mapped_surface_nodes_p1, res1 = map_surface_residues_to_graph(graph_p1, surface_residues_p1)\n",
    "    mapped_surface_nodes_p2, res2 = map_surface_residues_to_graph(graph_p2, surface_residues_p2)\n",
    "    \n",
    "    # Get nodes and edges for subgraphs\n",
    "    nodes_p1, edges_p1 = extract_subgraph(graph_p1, mapped_surface_nodes_p1)\n",
    "    nodes_p2, edges_p2 = extract_subgraph(graph_p2, mapped_surface_nodes_p2)\n",
    "    \n",
    "    # Concatenate node features\n",
    "    x = torch.cat((nodes_p1, nodes_p2), dim=0)\n",
    "    \n",
    "    # Offset edges for p2 and concatenate\n",
    "    edge_index_p2 = edges_p2 + nodes_p1.size(0)  # Offset edges for p2 nodes\n",
    "    edge_index = torch.cat((edges_p1, edge_index_p2), dim=1)\n",
    "    \n",
    "    # Define label for the protein\n",
    "    y = torch.tensor([class_label], dtype=torch.long)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ca930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def main():\n",
    "    # Load the CSV dataset containing protein pairs and class labels\n",
    "    #df_pairs = pd.read_csv('demo.csv')  # Load your dataset here (replace demo.csv with actual file)\n",
    "    #logger.info(\"Dataset loaded successfully\")\n",
    "    \n",
    "    \n",
    "    sasa_threshold = 0.90\n",
    "    output_graphs = \"graphs_demo\"\n",
    "    output_sasa = \"sasa_demo\"\n",
    "    \n",
    "    sasas = \"all_sasa_results.pkl\"\n",
    "    \n",
    "    graphs = \"all_graph_results.pkl\"\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate SASA results for the current protein\n",
    "    sasa_results = load_data(os.path.join(output_sasa, sasas))\n",
    "    surface_residues = filter_surface_residues(sasa_results, sasa_threshold)\n",
    "    \n",
    "    # Load all graphs for verification\n",
    "    loaded_graphs = load_all_graphs(os.path.join(output_graphs, graphs))\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "    #print(surface_residues_p1)\n",
    "    #print(f\"Loaded Graphs: {list(loaded_graphs_p1.keys())}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_pairs = pd.read_csv('demo.csv')  # Load your dataset here (replace demo.csv with actual file)\n",
    "    logger.info(\"Dataset loaded successfully\")\n",
    "    # Iterate over protein pairs and generate feature vectors\n",
    "    data_list = []\n",
    "    \n",
    "    logger.info(\"Start creating protein data object\")\n",
    "    for index, row in df_pairs.iterrows():\n",
    "        protein1 = row['P1']  # Assuming 'P1' is the protein 1 column\n",
    "        protein2 = row['P2']  # Assuming 'P2' is the protein 2 column\n",
    "        class_label = row['class']\n",
    "        \n",
    "        \n",
    "        surface_residues_list_p1 = surface_residues[protein1]\n",
    "        graph_ntw_p1 = loaded_graphs[protein1]\n",
    "        mapped_surface_nodes_p2, residue_dict_p2 = map_surface_residues_to_graph(graph_ntw_p1, surface_residues_list_p1)\n",
    "        \n",
    "        surface_residues_list_p2 = surface_residues[protein2]\n",
    "        graph_ntw_p2 = loaded_graphs[protein2]\n",
    "        mapped_surface_nodes_p2, residue_dict_p2 = map_surface_residues_to_graph(graph_ntw_p2, surface_residues_list_p2)\n",
    "        \n",
    "        #print(graph_ntw_p2)\n",
    "        \n",
    "        # Create the Data object\n",
    "        protein_data = create_protein_data(graph_ntw_p1, graph_ntw_p2, surface_residues_list_p1, surface_residues_list_p2, class_label)\n",
    "        data_list.append(protein_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # Save the data_list to a file\n",
    "    torch.save(data_list, 'data_list3.pt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91c89314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 18:26:56,615 - INFO - Dataset loaded successfully\n",
      "2024-11-27 18:26:56,615 - INFO - Start creating protein data object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All graphs loaded from graphs_demo\\all_graph_results.pkl\n",
      "Graph with 423 nodes and 725 edges\n",
      "Graph with 907 nodes and 1376 edges\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
